{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - 1.4 Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Global functions and variables\"\"\"\n",
    "\n",
    "import pymysql\n",
    "\n",
    "def open_conn():\n",
    "    \"\"\"open the connection before each test case\"\"\"\n",
    "    conn = pymysql.connect(user='public', password='ece656yelp',\n",
    "                                   host='maindb.czbva1am4d4u.us-east-2.rds.amazonaws.com',\n",
    "                                   database='yelp_db')\n",
    "    return conn\n",
    "\n",
    "def close_conn(conn):\n",
    "    \"\"\"close the connection after each test case\"\"\"\n",
    "    conn.close()\n",
    "\n",
    "def executeQuery(conn, query, commit=False):\n",
    "    \"\"\" fetch result after query\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    query_num = query.count(\";\")\n",
    "    if query_num > 1:\n",
    "        for result in cursor.execute(query, params=None, multi=True):\n",
    "            if result.with_rows:\n",
    "                result = result.fetchall()\n",
    "    else:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "    # we commit the results only if we want the updates to Can't leave a review dated before account creationthe database\n",
    "    # to persist.\n",
    "    if commit:\n",
    "        conn.commit()\n",
    "    else:\n",
    "        conn.rollback()\n",
    "    # close the cursor used to execute the query\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "yelp_conn = open_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_funclib\n",
    "\n",
    "import pymysql\n",
    "import nltk\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from random import shuffle\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def find_features(review, frequent_words):\n",
    "    '''Find the which words in the review are contained within the word_features\n",
    "    what were determined from the movie review dataset'''\n",
    "    words = review.split()\n",
    "    features = dict.fromkeys(frequent_words, False)\n",
    "    for word in words:\n",
    "        if word in frequent_words:\n",
    "            features[word] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "def isEnglish(text):\n",
    "    try:\n",
    "        text.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def build_dataset_from_query(query, documents, all_words, label):\n",
    "    '''Takes in the raw data from the SQL query and performs POS tagging as well as\n",
    "    cleans the data to remove foreign language reviews and symbols'''\n",
    "    for review in project_funclib.executeQuery(query):\n",
    "        text = review[0].replace('-', ' ').replace('/', ' ').replace('.', ' ').lower()\n",
    "        if not isEnglish(text):\n",
    "            continue\n",
    "        documents.append((text, label))\n",
    "        words = nltk.tokenize.word_tokenize(text)\n",
    "        POS = nltk.tag.pos_tag(words)\n",
    "        #  [print(word, tag) for word, tag in POS if tag.startswith('J')]\n",
    "        [all_words.append(w.lower()) for w, tag in POS if tag.startswith(('J', 'R'))]\n",
    "    return\n",
    "\n",
    "\n",
    "def build_feature_set(spam_query, ham_query):\n",
    "    '''Takes in the raw data from the SQL query and formats it correctly for\n",
    "    the NLTK classifier'''\n",
    "    documents = []\n",
    "    all_words = []\n",
    "    build_dataset_from_query(spam_query, documents, all_words, 'spam')\n",
    "    build_dataset_from_query(ham_query, documents, all_words, 'ham')\n",
    "    # list of all words of interest from reviews (determined by select_tags\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    # Select the top N most frequent words from this list to select as words\n",
    "    # that indicate a review is spam\n",
    "    word_features = set(list(all_words.keys())[:5000])\n",
    "    feature_sets = [(find_features(review, word_features), category) for\n",
    "                    (review, category) in documents]\n",
    "    shuffle(feature_sets)\n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "def build_sk_feature_set(spam_query, ham_query):\n",
    "    '''Takes in the raw data from the SQL query and formats it correctly for\n",
    "    the sklearn classifiers'''\n",
    "    documents = []\n",
    "    all_words = []\n",
    "    y = []\n",
    "    orpus = []\n",
    "    build_dataset_from_query(spam_query, documents, all_words, 'spam')\n",
    "    build_dataset_from_query(ham_query, documents, all_words, 'ham')\n",
    "    for text, label in documents:\n",
    "        y.append(label)\n",
    "        orpus.append(text)\n",
    "    cv = CountVectorizer(max_features=5000)\n",
    "    x = cv.fit_transform(orpus).toarray()\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def naive_bayes_classifier(training_set, testing_set):\n",
    "    classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, testing_set)\n",
    "    classifier.show_most_informative_features(5)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def gaussianNB_classifier(X_train, X_test, y_train, y_test):\n",
    "    '''Applies sklearn's gaussianNB algorithm to the feature set'''\n",
    "\n",
    "    gaussian_nb_classifier = GaussianNB()\n",
    "    gaussian_nb_classifier.fit(X_train, y_train)\n",
    "    pred = gaussian_nb_classifier.predict(X_test)\n",
    "    print('gaussianNB Accuracy score: {}'.format(accuracy_score(y_test, pred)))\n",
    "    print('gaussianNB Precision score: {}'.format(precision_score(y_test, pred)))\n",
    "    print('gaussianNB Recall score: {}'.format(recall_score(y_test, pred)))\n",
    "    print('gaussianNB F1 score: {}'.format(f1_score(y_test, pred)))\n",
    "\n",
    "\n",
    "def random_forest_classifier(X_train, X_test, y_train, y_test):\n",
    "    '''Applies sklearn's random forest algorithm to the feature set'''\n",
    "\n",
    "    classifier1 = RandomForestClassifier(n_estimators=15, criterion='entropy')\n",
    "    classifier1.fit(X_train, y_train)\n",
    "    predRF = classifier1.predict(X_test)\n",
    "    print('RF Accuracy score: {}'.format(accuracy_score(y_test, predRF)))\n",
    "    print('RF Precision score: {}'.format(precision_score(y_test, predRF)))\n",
    "    print('RF Recall score: {}'.format(recall_score(y_test, predRF)))\n",
    "    print('RF F1 score: {}'.format(f1_score(y_test, predRF)))\n",
    "\n",
    "\n",
    "def train_classifiers(category, ages, num_results, num_reviews):\n",
    "    '''Executes the SQL queries to get the necessary data and calls the\n",
    "    classification algorithms on the data after it is formatted correctly'''\n",
    "\n",
    "    spam_query = \"SELECT text FROM (SELECT text, business_id, user_id, date from review \\\n",
    "            WHERE useful = 0 AND funny = 0 AND cool = 0) as c JOIN\\\n",
    "            (SELECT id, yelping_since from user where average_stars = (5 or 1) AND review_count = 1)\\\n",
    "            AS a ON a.id=c.user_id JOIN (select business_id from category WHERE\\\n",
    "            category = '%s') as b USING(business_id) WHERE\\\n",
    "            c.date - a.yelping_since BETWEEN %d and %d limit %d;\"\\\n",
    "            % (category, ages[0]*100000000000, ages[1]*100000000000, num_results)\n",
    "    ham_query = \"SELECT text FROM review JOIN (select id from user where\\\n",
    "            review_count > %d) as a ON a.id=review.user_id JOIN (SELECT\\\n",
    "            business_id from category where category='%s') as b on\\\n",
    "            review.business_id=b.business_id limit %d\" % (num_reviews, category, num_results)\n",
    "    # Build the feature sets from the reviews returned by each query\n",
    "    # They will each be labeled spam or ham (ham are not spam)\n",
    "    feature_sets = build_feature_set(spam_query, ham_query)\n",
    "    len_data = int(len(feature_sets) * 0.5)\n",
    "    training_set = feature_sets[:len_data]\n",
    "    testing_set = feature_sets[len_data:]\n",
    "    # These are additional classification algorithms that were tried but\n",
    "    # removed to speed up computation time\n",
    "    #  x, y = build_sk_feature_set(spam_query, ham_query)\n",
    "    #  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30)\n",
    "    #  random_forest_classifier(X_train, X_test, y_train, y_test)\n",
    "    #  gaussianNB_classifier(X_train, X_test, y_train, y_test)\n",
    "    return naive_bayes_classifier(training_set, testing_set)\n",
    "\n",
    "\n",
    "num_results = 1000  # Total number of results to analyze from each query to speed up execution\n",
    "age = (0, 0)  # The time between account creation and the first review for accounts with 1 review\n",
    "category = 'Restaurants'  # The category of businesses to analyze\n",
    "num_reviews = 10  # The number of reviews an account has to leave to be classified as not spam\n",
    "\n",
    "# Analyze the number of reviews between 2 and 101 as the minimum required to not be spam\n",
    "accuracy = []\n",
    "for num_reviews in range(2, 21, 2):\n",
    "    accuracy.append(train_classifiers(category, age, num_results, num_reviews))\n",
    "\n",
    "pyplot.figure(1)\n",
    "pyplot.plot(range(0, 101, 10), accuracy)\n",
    "pyplot.xlabel('review_count by User')\n",
    "pyplot.ylabel('Spam Detection Accuracy')\n",
    "\n",
    "# Analyze ages of reviews between 0 and 7 days, with 0 having the biggest population\n",
    "accuracy = []\n",
    "ages_high = [0]\n",
    "ages_low = [0]\n",
    "[ages_high.append(i) for i in range(6)]\n",
    "[ages_low.append(i) for i in range(1, 7)]\n",
    "for age_low, age_high in zip(ages_low, ages_high):\n",
    "    ages = (age_low, age_high)\n",
    "    accuracy.append(train_classifiers(category, ages, num_results, num_reviews))\n",
    "\n",
    "pyplot.figure(2)\n",
    "pyplot.plot(ages_low, accuracy)\n",
    "pyplot.xlabel('Time Between Account Creation and First Review (days)')\n",
    "pyplot.ylabel('Spam Detection Accuracy')\n",
    "\n",
    "# Analyze the accuracy of spam detection across different categories of businesses\n",
    "accuracy = []\n",
    "categories = ['Restaurants', 'Health & Medical', 'Shopping', 'Beauty & Spas',\n",
    "              'Home Services', 'Nightlife', 'Automotive']\n",
    "for category in categories:\n",
    "    accuracy.append(train_classifiers(category, age, num_results, num_reviews))\n",
    "\n",
    "pyplot.figure(3)\n",
    "pyplot.plot(categories, accuracy)\n",
    "pyplot.xlabel('Business Category')\n",
    "pyplot.ylabel('Spam Detection Accuracy')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions for determining which reviews are SPAM:  \n",
    "Accuracy with WHERE review_count = 1: 61%  \n",
    "Accuracy with WHERE review_count = 1 AND review.useful = 0 AND review.funny = 0 AND review.cool = 0: 62%  \n",
    "Expanding POS tags looked at to include verbs on top of adjective and adverbs: 63%  \n",
    "Look at the top 100 frequently appearing words instead of 1000: 53%  \n",
    "Look at the top 5000 frequently appearing words instead of 1000: 66%  \n",
    "Reducing POS tags looked at just adjectives: 67%  \n",
    "Remove non-english reviews and replacing - and / with spaces: 67%  \n",
    "Add review.date -yelping_since = 0: 70%  \n",
    "Change query to 'SELECT text FROM user join review on user.id=review.user_id where average_stars =  5 or average_stars = 1': 71%  \n",
    "Change query to 'SELECT text FROM review JOIN user ON user.id=review.user_id WHERE review_count = 1 AND review.useful = 0 AND review.funny = 0 AND review.cool = 0 AND review.date - yelping_since and average_stars = 5 limit 1000': 76%  \n",
    "Change query to 'SELECT text FROM review JOIN user ON user.id=review.user_id WHERE review_count = 1 AND review.useful = 0 AND review.funny = 0 AND review.cool = 0 AND review.date - yelping_since and average_stars = 1 limit 1000': 80%  \n",
    "Change query to only include restaurants: 83%\n",
    "Change query to only include hotels: 85%\n",
    "Change query to only include restaurants: 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods \n",
    "Now that we're confident that the data is sufficiently cleaned as to not produce erroneous results from our analysis outside of those of interest, we can begin performing the actual analysis of trends in the data. The trend that was analyzed is the affect different attributes about users and their reviews have on the likelihood that their review is spam. These attributes include the type of business being reviewed, the ratings of the reviews left by users, the average_stars of the user, the time between account creation and  and the review_count of the user. In order to determine if a given query returns reviews that are spam a machine learning classifier was used that implemented a bag-of-words model and applied a naive Bayes and random forest classifier onto this model. The metric we looked at to determine the liklihood that a review is spam is the accuracy of the classifier in classifying the suspected spam reviews when mixed with reviews that are not spam.  \n",
    "The bag-of-words model takes each spam and not spam review and looks at the words that occur most frequently in the reviews to use those as features. In this case we looked at the top 5000 most occuring adjectives and adverbs in the review to use as features. We found the adjectives and adverbs using NLTK's part of speech tagging on every review and decided to go with these parts of speech because they are the words of interest in reviews in general and provide and easy way to eliminate frequently occuring words in general that are not specific to reviews (ex. 'the' and 'it').  \n",
    "Classification was performed initially using only a naive Bayes classifier that is built into the NLTK library which uses Bayes theorem to determine the probability that a review is spam given the probability that each feature (word) in the review is spam. If this probability is over 50% then that review is classified as spam. Later on other classificiation algorithms were tried to see if a better classification accuracy could be achieved such as scikit-learn's random forest classifier and gaussian naive Bayes, however in general these algorithms performed worse than NLTK's naive Bayes classifier so it was the only one used to save computation time.  \n",
    "Accuracy of the spam prediction was determined by splitting the shuffled spam and ham reviews in half, with one half becoming the training set to train the classifier on, and the other half becoming the testing set which the spam classifier is tested on to determine its accuracy.\n",
    "The metrics analyzed were:\n",
    "* Categories - Restaurants, Health & Medical, Shopping, Beauty & Spas, Home Services, Nightlife and Automotive were lo\n",
    "* Age - Time between account creation and first review for potential bot accounts with only a single review, looked between 0 and 6 days one day at a time\n",
    "* number of reviews - The minimum numbers of reviews that an accounts needs to leave to not be classified as spam\n",
    "* number of results - the number of rows from each query that were analyzed, this was left fixed at 1000 for speed\n",
    "\n",
    "### Results\n",
    "![Figure 1](../../pythonAnalysis/figures/1_review_stars.png)\n",
    "It was found that the longer someone waited to leave their first review from account creation, the less likely it was to be spam. This was expected as any bot account that is created to simply boost up the score of a restaurant would leave a review immediately after creation, as opposed to a real user that may make their account and then not leave a review on a business until they go to one a while later. The downside of this metric is that there are also many real used that create account while at a business and leave an overly positive or negative review because its fresh in their memory.  \n",
    "![Figure 2](../../pythonAnalysis/figures/categories.png)\n",
    "Next, it was found that amoungst the different categories of businesses that Automotive businesses were the least likely to have spam reviews, while shopping locations were the most. Analyzing this further reveals that on average the automotive customers were more likely to have accounts with only one review for the automotive business, suggesting automotive people are less likely to be active users versus shopping locations which have legitimate users that are more active Yelp users so the ones with only one review are more likely to be spam.  \n",
    "![Figure 3](../../pythonAnalysis/figures/avg_stars.png)\n",
    "It was also found that the average_stars of the users' account influences the likelihood that their reviews are spam in that if a users' average_stars is 5 or 1 versus if their average_stars is some other value showing that they've given other reviews besides just the top score or the lowest. This metric would miss spam users that use their account for spamming both high and low, instead of only doing one or the other.\n",
    "\n",
    "### Future Work\n",
    "While classifiers for spam emails are quite well established, spam classifiers for reviews are more challenging because they lack many of the features that are indicative of spam such as including links or using language that suggests that the person is trying to sell something. However, this is an active area of research and there are other more complex features that have been identified that have been shown to indicate a review is spam such as:\n",
    "[reference: http://www.aclweb.org/anthology/P14-1147]\n",
    "* Using a separate gold standard dataset of honest and deceptive reviews to train with instead of using approximations from the dataset\n",
    "* Look for spacial details in a review to indicate honesty (ex. terms such as “bathroom”) while deceptive reviews will talk about general concepts such as why or with whom they went to the hotel\n",
    "* Using Bayesian learning to analyze multiple of these metrics together to draw a more definitive conclusion\n",
    "* Checking for if there are many grammatical and spelling mistakes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
